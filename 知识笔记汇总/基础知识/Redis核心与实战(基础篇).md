## 基础篇

### 1、基本架构

一个键值数据库包括了**访问框架、索引模块、操作模块和存储模块**四部分

**访问模式**通常有两种：一种是通过函数库调用的方式供外部应用使用；另一种是通过网络框架以 Socket 通信的形式对外提供键值对操作。

**索引**的作用是让键值数据库根据 key 找到相应 value 的存储位置，进而执行操作。Redis 采用哈希表作为 key-value 索引

操作模块就实现了不同操作的具体逻辑：

- 对于 GET/SCAN 操作而言，此时根据 value 的存储位置返回 value 值即可；
- 对于 PUT 一个新的键值对数据而言，SimpleKV 需要为该键值对分配内存空间；
- 对于 DELETE 操作，SimpleKV 需要删除键值对，并释放相应的内存空间，这个过程由分配器完成。

从 SimpleKV 演进到 Redis，有以下几个重要变化：

1. Redis 主要通过网络框架进行访问，而不再是动态库了，这也使得 Redis 可以作为一个基础性的网络服务进行访问，扩大了 Redis 的应用范围。
2. Redis 数据模型中的 value 类型很丰富，因此也带来了更多的操作接口，例如面向列表的 LPUSH/LPOP，面向集合的 SADD/SREM 等。
3. Redis 的持久化模块能支持两种方式：日志（AOF）和快照（RDB），这两种持久化方式具有不同的优劣势，影响到 Redis 的访问性能和可靠性。
4. SimpleKV 是个简单的单机键值数据库，但是，Redis 支持高可靠集群和高可扩展集群，因此，Redis 中包含了相应的集群功能支撑模块。

### 2、数据结构

#### 键和值用什么结构组织？

为了实现从键到值的快速访问，Redis 使用了一个**哈希表**来保存**所有键值对**。

一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。哈希桶中的元素保存的**并不是值本身**，而是指向具体值的**指针**。哈希桶中的 entry 元素中保存了*key和*value指针，分别指向了实际的键和值

Redis 解决哈希冲突的方式，就是**链式哈希**。链式哈希也很容易理解，就是指同**一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接**。

当数据太多时，Redis会对哈希表做 **rehash** 操作。rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存。Redis 默认使用了**两个全局哈希表**：哈希表 1 和哈希表
2。一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。

随着数据逐步增多，Redis 开始执行 **rehash**，这个过程分为三步：

1、给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；

2、把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；

3、释放哈希表 1 的空间。

但是第二步涉及大量的数据拷贝，如果一次性把哈希表 1 中的数据都迁移完，会造成 Redis 线程阻塞，为了避免这个问题，Redis 采用了**渐进式 rehash**。

**渐进式 rehash**：Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1
中的下一个索引位置的 entries。**如果没有键值对操作时**，这个redis的定时任务会周期性地（例如每100ms一次）搬移一些数据到新的哈希表中，这样可以缩短整个rehash的过程。

#### 集合数据操作效率

集合类型的底层数据结构主要有 5 种：整数数组、双向链表、哈希表、压缩列表和跳表。

##### 压缩列表

压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 **zlbytes、zltail 和 zllen**，分别表示列表长度、列表尾的偏移量和列表中的 entry
个数；压缩列表在表尾还有一个 zlend，表示列表结束。**它跟数组不同的一点是，它允许存储的数据大小不同，数组要求每个元素的大小相同。**压缩列表这种存储结构，一方面比较节省内存，另一方面可以支持不同类型数据的存储。

如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。

##### 不同操作的复杂度

**单元素操作是基础；**

**范围操作非常耗时；**

**统计操作通常高效；**

**例外情况只有几个。**

**Redis 之所以能快速操作键值对，一方面是因为 O(1) 复杂度的哈希表被广泛使用**，包括 String、Hash 和 Set，它们的操作复杂度基本由哈希表决定，另一方面，Sorted Set 也采用了 O(logN)
复杂度的跳表。

**集合**类型的范围操作，因为要**遍历底层数据结构**，复杂度通常是 O(N)。这里，我的建议是：用其他命令来替代，例如可以用 SCAN 来代替，避免在 Redis 内部产生费时的全集合遍历操作。

复杂度较高的 **List 类型**，它的两种底层实现结构：双向链表和压缩列表的操作复杂度都是 O(N)。因此，因地制宜地使用 List 类型。**例如**，既然它的 POP/PUSH 效率很高，那么就将它主要用于 FIFO
队列场景，而不是作为一个可以随机读写的集合。

#### 问题：整数数组和压缩列表作为底层数据结构的优势是什么？

整数数组和压缩列表的设计，充分体现了 Redis“又快又省”特点中的**“省”，也就是节省内存空间**。

整数数组和压缩列表都是在内存中分配一块地址连续的空间，然后把集合中的元素一个接一个地放在这块空间内，非常紧凑。因为元素是挨个连续放置的，我们不用再通过额外的指针把元素串接起来，这就避免了额外指针带来的空间开销。

### 3、高性能IO模型

**通常说Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成**的，这也是 Redis 对外提供键值存储服务的主要流程。但 Redis的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。

#### Redis 为什么用单线程？

多线程的模式对共享资源的**并发控制**问题：1，若没有额外机制保证情况下，不能保证共享资源的准确性；2，添加额外机制可能带来额外的开销

采用多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统代码的易调试性和可维护性。为了避免这些问题，Redis 直接采用了单线程模式。

#### 单线程 Redis 为什么那么快？

一方面，Redis 的大部分操作在**内存上完成**，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因。

另一方面，就是 Redis 采用了**多路复用机制**，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。

#### Redis基本IO模型

**潜在的阻塞点，分别是 accept() 和 recv()。**

#### socket 网络模型支持非阻塞模式。

在 socket 模型中，不同操作调用后会返回不同的套接字类型。

socket() 方法会返回主动套接字，然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。最后，调用 accept() 方法接收到达的客户端连接，并返回已连接套接字。

针对监听套接字，我们可以设置非阻塞模式：当 Redis 调用 accept() 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。但是，你要注意的是，调用 accept() 时，已经存在监听套接字了。

针对已连接套接字设置非阻塞模式：Redis 调用 recv() 后，如果已连接套接字上一直没有数据到达，Redis 线程同样可以返回处理其他操作。

#### 基于多路复用的高性能 I/O 模型

**select/epoll 机制**简单来说，在 Redis 只运行单线程的情况下，**该机制允许内核中，同时存在多个监听套接字和已连接套接字**。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis
线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。

（多个 FD 就是刚才所说的多个套接字。Redis 网络框架调用 epoll 机制，让内核监听这些套接字）

为了在请求到达时能通知到 Redis 线程，select/epoll 提供了**基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。**

### 4、AOF(Append Only File)日志持久化

#### AOF 日志是如何实现的？

AOF 它是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志。

AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。

为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，**并不会先去对这些命令进行语法检查**。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。**
而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中**，否则，系统就会直接向客户端报错。

AOF 还有一个好处：它是在命令执行后才记录日志，所以**不会阻塞当前的写操作**。

**AOF 也有两个潜在的风险：**

1、如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险

2、AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。

这两个风险都是和 AOF **写回磁盘的时机**相关的。

#### 三种写回策略

其实，对于这个问题，AOF 机制给我们提供了三个选择，也就是 AOF 配置项 **appendfsync** 的三个可选值。

- Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；
- Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；
- No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。

分析：

- “**同步写回**”可以做到基本不丢数据，但是它在每一个写命令后都有一个慢速的落盘操作，**不可避免地会影响主线程性能**；
- 虽然“操作系统控制的写回”在写完缓冲区后，就可以继续执行后续的命令，但是落盘的时机已经不在 Redis 手中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的数据就丢失了；
- “**每秒写回**”采用一秒写回一次的频率，避免了“同步写回”的性能开销，虽然减少了对系统性能的影响，但是如果发生宕机，**上一秒内未落盘的命令操作仍然会丢失**。所以，这只能算是，在避免影响主线程性能和避免数据丢失两者间取了个折中。

#### AOF 文件过大带来的性能问题

性能问题主要在于以下三个方面：

一是，文件系统本身对文件大小有限制，无法保存过大的文件；

二是，如果文件太大，之后再往里面追加命令记录的话，效率也会变低；

三是，如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。

**AOF 重写机制**就是在重写时，Redis 根据数据库的现状创建一个新的 AOF 文件，重写机制具有“多变一”功能。所谓的“多变一”，也就是说，旧日志文件中的多条命令，在重写后的新日志中变成了一条命令。在重写的时候，是**根据这个键值对当前的最新状态**，为它生成对应的写入命令。

#### AOF重写过程

和 AOF 日志由主线程写回不同，**重写过程是由后台子进程 bgrewriteaof 来完成的**，这也是为了避免阻塞主线程，导致数据库性能下降。

**重写的过程总结为“一个拷贝，两处日志”**。

**一个拷贝**就是指，每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。

**“两处日志”**

第一处日志就是指**正在使用的 AOF 日志**，而第二处日志，就是指**新的 AOF 重写日志**。如果有新的操作需要写入，redis会讲这个操作分别写到两个日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF
文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。

> 这里只是想说在AOF重写过程中，新的更新请求仍然会写入到旧的AOF文件，即便在AOF重写过程中（此时新AOF文件还未生效）系统宕机了，redis依然可以借助旧的AOF文件把内存恢复到宕机前的状态（这里根据写会策略的不同，可能会丢失不同大小的数据）。

**每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。**

fork子进程，fork这个瞬间一定是会阻塞主线程的，fork采用操作系统提供的**写实复制(Copy On Write)机制**，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题，但fork子进程需要**拷贝进程必要的数据结构**，其中有一项就是拷贝内存页表（虚拟内存和物理内存的映射索引表），这个拷贝过程会消耗大量CPU资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork阻塞时间越久。

拷贝内存页表完成后，**子进程与父进程指向相同的内存地址空间**，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。如果父进程操作的是一个已经存在的key，那么这个时候父进程**就会真正拷贝这个key对应的内存数据，申请新的内存空间**，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。

#### 什么时候会触发AOF 重写呢？

有两个配置项在控制AOF重写的触发时机：

1、auto-aof-rewrite-min-size: 表示运行AOF重写时文件的最小大小，默认为64MB

2、auto-aof-rewrite-percentage:
这个值的计算方法是：当前AOF文件大小和上一次重写后AOF文件大小的差值，再除以上一次重写后AOF文件大小。也就是当前AOF文件比上一次重写后AOF文件的增量大小，和上一次重写后AOF文件大小的比值。

**AOF文件大小同时超出上面这两个配置项时，会触发AOF重写。**

#### 问题 1：AOF 重写过程中有没有其他潜在的阻塞风险？

风险一：Redis 主线程 fork 创建 bgrewriteaof 子进程时，**内核需要创建用于管理子进程的相关数据结构**，这些数据结构在操作系统中通常叫作**进程控制块（Process Control Block，简称为 PCB**）。内核要把主线程的 PCB 内容拷贝给子进程。这个创建和拷贝过程由内核执行，是会阻塞主线程的。而且，在拷贝过程中，子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis实例内存大，页表就会大，fork 执行时间就会长，这就会给主线程带来阻塞风险。

风险二：bgrewriteaof 子进程会和主线程**共享内存**。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 **bigkey，也就是数据量大的集合类型数据**，那么，主线程会因为申请大空间而面临阻塞风险。因为操作系统在分配内存空间时，有查找和锁的开销，这就会导致阻塞。

#### 问题 2：AOF 重写为什么不共享使用 AOF 本身的日志？

如果都用 AOF 日志的话，主线程要写，bgrewriteaof 子进程也要写，这两者会竞争文件系统的锁，这就会对 Redis 主线程的性能造成影响。

### 5、内存快照-RDB(Redis DataBase)

**所谓内存快照，就是指内存中的数据在某一个时刻的状态记录。**

Redis 的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是**全量快照**，也就是说，把内存中的所有数据都记录到磁盘中。

Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。

- save：在主线程中执行，会导致阻塞；
- bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，**这也是 Redis RDB 文件生成的默认配置。**

为了快照的完整性，也允许主线程同时对数据进行修改。所以这个时候，Redis 就会借助操作系统提供的**写时复制技术（Copy-On-Write, COW**），在执行快照的同时，正常处理写操作。

简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。

此时，如果主线程对这些数据也都是**读操作**（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。

但是，如果主线程要**修改一块数据**（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，**主线程仍然可以直接修改原来的数据**。

> “这块数据就会被复制一份，生成该数据的副本”，这个操作在实际执行过程中，是子进程复制了主线程的页表，所以通过页表映射，能读到主线程的原始数据，而当**有新数据写入或数据修改时**，**主线程**会把新数据或修改后的数据写到一个**新的物理内存地址上**，并修改主线程自己的页表映射。所以，子进程读到的类似于原始数据的一个副本，而主线程也可以正常进行修改。

#### 多久存一次RDB文件

如果频繁地执行全量快照，也会带来两方面的开销：

1、频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。

2、fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。

~~此时，我们可以做**增量快照**，所谓增量快照，就是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。~~

Redis 4.0 中提出了一个**混合使用 AOF 日志和内存快照的方法**。简单来说，**内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。**

如下图所示，T1 和 T2 时刻的修改，用 AOF 日志记录，等到第二次做全量快照时，就可以清空 AOF 日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。

#### 关于 AOF 和 RDB 的选择问题，三点建议：

- 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；
- 如果允许分钟级别的数据丢失，可以只使用 RDB；
- 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。

#### 问题：

使用一个 2 核 CPU、4GB 内存、500GB 磁盘的云主机运行 Redis，Redis 数据库的数据量大小差不多是 2GB。当时 Redis 主要以修改操作为主，写读比例差不多在 8:2 左右，也就是说，如果有 100 个请求，80
个请求执行的是修改操作。在这个场景下，用 RDB 做持久化有什么风险吗？

**内存不足的风险**：Redis fork 一个 bgsave 子进程进行 RDB 写入，如果主线程再接收到写操作，就会采用写时复制。写时复制需要给写操作的数据分配新的内存空间。本问题中写的比例为 80%，那么，在持久化过程中，为了保存
80% 写操作涉及的数据，写时复制机制会在实例内存中，为这些数据再分配新内存空间，分配的内存量相当于整个实例数据量的 80%，大约是 1.6GB（潜在的可能性），这样一来，**整个系统内存的使用量就接近饱和了**。此时，如果实例还有**
大量的新 key 写入**或 key 修改，云主机内存很快就会被吃光。如果云主机开启了 Swap 机制，就会有一部分数据被换到磁盘上，当访问磁盘上的这部分数据时，性能会急剧下降。如果云主机没有开启 Swap，会直接触发 OOM，整个
Redis 实例会面临被系统 kill 掉的风险。

**主线程和子进程竞争使用 CPU 的风险**：生成 RDB 的子进程需要 CPU 核运行，主线程本身也需要 CPU 核运行，而且，如果 Redis 还启用了后台线程，此时，主线程、子进程和后台线程都会竞争 CPU 资源。由于云主机只有 2
核 CPU，这就会影响到主线程处理请求的速度。

### 6、数据同步-主从库

Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是**读写分离**的方式。

- 读操作：主库、从库都可以接收；
- 写操作：首先到主库执行，然后，主库将写操作同步给从库。

#### 主从库间如何进行第一次同步？

当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。

例如，现在有实例 1（ip：172.16.19.3）和实例 2（ip：172.16.19.5），我们**在实例 2 上执行**以下这个命令后，**实例 2** 就变成了实例 1 的**从库**，并从实例 1 上复制数据：

```
replicaof  172.16.19.3  6379
```

1、**第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。**

在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。具体来说，从库给主库发送 **psync 命令**，表示要进行数据同步，主库根据这个命令的参数来启动复制。**psync 命令包含了主库的
runID 和复制进度 offset 两个参数**。

- runID，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为“？”。
- offset，此时设为 -1，表示第一次复制。

**主库收到 psync 命令后**，会用 FULLRESYNC 响应命令带上两个参数：**主库 runID** 和**主库目前的复制进度 offset**，返回给从库。从库收到响应后，会记录下这两个参数。

这里有个地方需要注意，**FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。**

2、**第二阶段，主库将所有数据同步给从库。**

**从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件。**

主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会**先清空当前数据库，然后加载 RDB 文件**。

在主库将数据同步给从库的过程中，主库仍然可以正常接收请求。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。**为了保证主从库的数据一致性**，主库会在内存中用专门的 **replication buffer**，记录
RDB 文件**生成后收到的所有写操作**。

3、第三个阶段，主库会把第二阶段执行过程中**新收到的写命令**，再发送给从库。

具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。

#### 主从级联模式分担全量复制时的主库压力

我们可以通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。

简单来说，我们在部署主从集群的时候，可以**手动选择一个从库（比如选择内存资源配置较高的从库**），用于级联其他的从库。然后，我们可以再选择一些从库执行如下命令，让它们和刚才所选的从库，建立起主从关系。

```
replicaof  所选从库的IP 6379
```

这些从库在进行同步时，**不用再和主库进行交互了，只要和级联的从库**进行写操作同步就行了，这就可以减轻主库上的压力

#### 主从库间网络断了怎么办？:question:

从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步。

当**主从库断连后**，replication buffer丢失，repl_backlog_buffer仍然存在, **主库会把断连期间收到的写操作命令写入** **repl_backlog_buffer**
这个缓冲区。当主从库重新建立连接后，主库只用把repl_backlog_buffer中位于 master_repl_offset 和 slave_repl_offset 之间的命令操作通过replication buffer同步给从库就行。

repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。

对主库来说，对应的偏移量就是 master_repl_offset,从库已复制的偏移量 slave_repl_offset。

主从库的连接恢复之后，**从库首先**会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset
之间的差距。此时，主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。

因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，**就会覆盖掉之前写入的操作**
。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。

一般而言，我们可以调整 repl_backlog_size 这个参数。这个参数和所需的缓冲空间大小有关，我们通常需要把这个缓冲空间扩大一倍，即 repl_backlog_size = 缓冲空间大小 * 2

缓冲空间的计算公式是：缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。

#### replication buffer 和 repl_backlog_buffer 的区别

replication buffer 是主从库在进行全量复制时，主库上用于和从库连接的客户端的 buffer，而 repl_backlog_buffer 是为了支持从库增量复制，主库上用于持续保存写操作的一块专用 buffer。

Redis 主从库在进行复制时，当主库要把全量复制期间的写操作命令发给从库时，主库会先创建一个客户端，用来连接从库，然后通过这个客户端，把写操作命令发给从库。在内存中，主库上的客户端就会对应一个 buffer，这个 buffer 就被称为
replication buffer。Redis 通过 client_buffer 配置项来控制这个 buffer 的大小。主库会给每个从库建立一个客户端，**所以 replication buffer
不是共享的，而是每个从库都有一个对应的客户端。**

repl_backlog_buffer 是一块专用 buffer，在 Redis
服务器启动后，开始一直接收写操作命令，这是所有从库共享的。主库和从库会各自记录自己的复制进度，所以，不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步。在repl_backlog_buffer中找主从差异的数据后，如何发给从库呢？这就用到了replication
buffer。

#### 问题：为什么主从库间的复制不使用 AOF？

1. RDB 文件是二进制文件，无论是要把 RDB 写入磁盘，还是要通过网络传输 RDB，IO 效率都比记录和传输 AOF 的高。
2. 在从库端进行恢复时，用 RDB 的恢复效率要高于用 AOF。

### 7、哨兵机制

在 Redis 主从集群中，哨兵机制是实现主从库自动切换的关键机制

哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。

**监控**是指哨兵进程在运行时，**周期性地给所有的主从库发送 PING 命令**，检测它们是否仍然在线运行。如果库没有在规定时间内响应哨兵的 PING 命令，哨兵就会把它标记为“**下线状态**”

#### 主观下线和客观下线

哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“**主观下线**”。

**误判**一般会发生在集群网络压力较大、网络拥塞，或者是主库本身压力较大的情况下。

**哨兵集群**，采用多实例组成的集群模式进行部署，引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。

在判断主库是否下线时，不能由一个哨兵说了算，只有大多数的哨兵实例，都判断主库已经“主观下线”了，主库才会被标记为“**客观下线**”

简单来说，“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。（当然，有多少个实例做出“主观下线”的判断才可以，可以由 Redis 管理员自行设定）。

#### 如何选定新主库？

一般来说，把哨兵选择新主库的过程称为“**筛选 + 打分**”。简单来说，我们在多个从库中，先按照**一定的筛选条件**，**把不符合条件的从库去掉**。然后，我们再按照**一定的规则**，给剩下的从库逐个打分，将得分最高的从库选为新主库，如下图所示：

**在选主时，除了要检查从库的当前在线状态，还要判断它之前的网络连接状态。**

**规则：三轮打分：从库优先级、从库复制进度以及从库 ID 号**

只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束。

第一轮：优先级最高的从库得分高。

第二轮：和旧主库同步程度最接近的从库得分高。

**我们想要找的从库，它的 slave_repl_offset 需要最接近 master_repl_offset**。如果在所有从库中，有从库的 slave_repl_offset 最接近
master_repl_offset，那么它的得分就最高，可以作为新主库。

第三轮：ID 号小的从库得分高。

**总的来说：首先，哨兵会按照在线状态、网络状态，筛选过滤掉一部分不符合要求的从库，然后，依次按照优先级、复制进度、ID 号大小再对剩余的从库进行打分，只要有得分最高的从库出现，就把它选为新主库。**

#### 问题 1：在主从切换过程中，客户端能否正常地进行请求操作呢？

主从集群一般是采用读写分离模式，当主库故障后，客户端仍然可以把读请求发送给从库，让从库服务。但是，对于写请求操作，客户端就无法执行了（失败持续的时间 = 哨兵切换主从的时间 + 客户端感知到新主库 的时间）。

#### 问题 2：如果想要应用程序不感知服务的中断，还需要哨兵或客户端再做些什么吗？

一方面，**客户端需要能缓存应用发送的写请求**。只要不是同步写操作（Redis 应用场景一般也没有同步写），写请求通常不会在应用程序的关键路径上，所以，客户端缓存写请求后，给应用程序返回一个确认就行。

另一方面，主从切换完成后，客户端要能和新主库重新建立连接，哨兵需要提供订阅频道，让客户端能够订阅到新主库的信息。同时，客户端也需要能主动和哨兵通信，询问新主库的信息。

### 8、哨兵集群

#### 基于 pub/sub 机制的哨兵集群组成

在配置哨兵的信息时，我们只需要用到下面的这个配置项，**设置主库的 IP 和端口**，并没有配置其他哨兵的连接信息。

```
sentinel monitor <master-name> <ip> <redis-port> <quorum> 
```

**哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub/sub 机制，也就是发布 / 订阅机制。**

哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。同时，它也可以从主库上订阅消息，获得**其他哨兵发布的连接信息**。

Redis 会以频道的形式，对这些消息进行分门别类的管理。只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。

在主从集群中，主库上有一个名为“`__sentinel__:hello`”的频道，不同哨兵就是通过它来相互发现，实现互相通信的。

**哨兵是如何知道从库的 IP 地址和端口的呢？**

这是**由哨兵向主库发送 INFO 命令来完成的**。

就像下图所示，哨兵 2 给主库发送 INFO 命令，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控。哨兵 1 和 3
可以通过相同的方法和从库建立连接。

#### 基于 pub/sub 机制的客户端事件通知

从本质上说，**哨兵就是一个运行在特定模式下的 Redis 实例**，只不过它并不服务请求操作，只是完成**监控、选主和通知**的任务。所以，每个哨兵实例也提供 pub/sub 机制，**客户端可以从哨兵订阅消息**
。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。

#### 由哪个哨兵执行主从切换？

哨兵集群要判定主库“客观下线”，需要有一定数量的实例都认为该主库已经“主观下线”了。

任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票。

一个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵配置文件中的 quorum 配置项设定的。

在投票过程中，任何一个想成为 Leader 的哨兵，要满足两个条件：

第一，拿到半数以上的赞成票；

第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。

需要注意的是，**如果哨兵集群只有 2 个实例，此时，一个哨兵要想成为 Leader，必须获得 2 票**，而不是 1 票。所以，如果有个哨兵挂掉了，那么，此时的集群是无法进行主从库切换的。因此，通常我们至少会配置 3 个哨兵实例。

一个经验：**要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds。**

#### 问题 1：

5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障了，此时，Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？如果可以的话，还能进行主从库自动切换吗？

因为判定主库“客观下线”的依据是，认为主库“主观下线”的哨兵个数要大于等于 quorum 值，现在还剩 2 个哨兵实例，个数正好等于 quorum 值，所以**还能正常判断主库是否处于“客观下线”状态。**

如果一个哨兵想要执行主从切换，就要获到**半数以上的哨兵投票赞成**，也就是至少需要 3 个哨兵投票赞成。但是，现在只有 2 个哨兵了，所以就**无法进行主从切换**了。

#### 问题 2：哨兵实例是不是越多越好呢？如果同时调大 down-after-milliseconds 值，对减少误判是不是也有好处？

哨兵实例越多，误判率会越低，但是在判定主库下线和选举 Leader 时，实例需要拿到的赞成票数也越多，等待所有哨兵投完票的时间可能也会相应增加，**主从库切换的时间也会变长**
，客户端容易堆积较多的请求操作，可能会导致客户端请求溢出，从而造成请求丢失。如果业务层对 Redis 的操作有响应时间要求，就可能会因为新主库一直没有选定，新操作无法执行而发生超时报警。

调大 down-after-milliseconds 后，可能会导致这样的情况：主库实际已经发生故障了，但是**哨兵过了很长时间才判断出来**，这就会影响到 Redis 对业务的可用性。

### 9、切片集群

切片集群，也叫分片集群，就是指启动多个 Redis 实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。

#### 数据切片和实例的对应分布关系

从 3.0 开始，官方提供了一个名为 Redis Cluster 的方案，用于实现切片集群。Redis Cluster 方案中就规定了数据和实例的对应规则。

Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和实例之间的映射关系。在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的
key，被映射到一个哈希槽中。

**具体的映射过程**分为两大步：

首先根据键值对的 key，按照CRC16 算法计算一个 16 bit 的值；

然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的**模数**，**每个模数代表一个相应编号的哈希槽。**

部署 Redis Cluster 方案时，可以使用 cluster create 命令创建集群，此时，Redis 会自动把这些槽平均分布在集群实例上。例如，如果集群中有 N 个实例，那么，每个实例上的槽个数为 16384/N 个。

> 当然， 我们也可以使用 cluster meet 命令手动建立实例间的连接，形成集群，再使用 cluster addslots 命令，指定每个实例上的哈希槽个数。

```
redis-cli -h 172.16.19.3 –p 6379 cluster addslots 0,1
redis-cli -h 172.16.19.4 –p 6379 cluster addslots 2,3
redis-cli -h 172.16.19.5 –p 6379 cluster addslots 4
```

⚠️**在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。**

#### 客户端如何定位数据？

客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。

**客户端收到哈希槽信息后，会把哈希槽信息缓存在本地**。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。

在集群中，**实例和哈希槽的对应关系并不是一成不变**的，最常见的变化有两个：

- 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽；
- 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。

**Redis Cluster 方案提供了一种重定向机制**，所谓的“重定向”，就是指，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令（实例会给客户端返回数据所在的新实例的位置）。

#### 问题：为什么 Redis 不直接用一个表，把键值对和实例的对应关系记录下来？

如果使用表记录键值对和实例的对应关系，一旦键值对和实例的对应关系发生了变化（例如实例有增减或者数据重新分布），就要修改表。如果是单线程操作表，那么所有操作都要串行执行，**性能慢**
；如果是多线程操作表，就涉及到加锁开销。此外，如果数据量非常大，使用表记录键值对和实例的对应关系，**需要的额外存储空间也会增加**。

基于哈希槽计算时，虽然也要记录哈希槽和实例的对应关系，但是**哈希槽的个数要比键值对的个数少很多**，无论是修改哈希槽和实例的对应关系，还是使用额外空间存储哈希槽和实例的对应关系，都比直接记录键值对和实例的关系的**开销小得多**。

### 主线程、子进程和后台线程的联系与区别

从操作系统的角度来看，**进程一般是指资源分配单元**，例如一个进程拥有自己的堆、栈、虚存空间（页表）、文件描述符等；

而**线程一般是指 CPU 进行调度和执行的实体**。

> 进程是系统进行资源分配和调度的一个独立单位.
>
> 线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源.

如果一个进程启动后，没有再创建额外的线程，那么，这样的进程一般称为**主进程或主线程**。

Redis 启动以后，本身就是一个进程，它会接收客户端发送的请求，并处理读写操作请求。而且，接收请求和处理请求操作是 Redis 的主要工作，Redis 没有再依赖于其他线程，所以，我一般把完成这个**主要工作的 Redis
进程，称为主进程或主线程**。

Redis 也开始使用 pthread_create 创建线程，这些线程在创建后，一般会**自行执行一些任务**，例如执行异步删除任务。相对于完成主要工作的主线程来说，我们一般可以称**这些线程为后台线程**。
